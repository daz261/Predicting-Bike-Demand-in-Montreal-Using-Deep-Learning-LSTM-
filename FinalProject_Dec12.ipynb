{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Bike Demand in Montreal Using Neural Network using LSTM\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have specifically decided to focus on the BIXI bike sharing system in Montreal, Canada, as it is the second largest bike sharing system in North America. Also, extensive datasets can be easily acquired on their website: https://montreal.bixi.com/en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset: We have used one-month worth of data  - July 2017 - to make predictions for the next month \n",
    "### Goals: \n",
    "1. Define two new parameters - net gain and cluster gain\n",
    "2. Make predictions on the level of occupancy of the stations (ie. how many bikes are station X at time Y and date Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steps:\n",
    "1. Data Preprocesing\n",
    "2. Clustering\n",
    "3. Define Station Gain\n",
    "4. Define Cluster Gain\n",
    "5. Run DNN, RNN and LSTM models\n",
    "6. Optimize the models in Step 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import folium\n",
    "import gpxpy.geo\n",
    "from datetime import datetime\n",
    "import time\n",
    "import seaborn as sns\n",
    "import os\n",
    "import math\n",
    "import xgboost as xgb\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg')\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "#from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "from sklearn.svm import SVC\n",
    "#HAD TO USE SVR - Support Vector Regression bc SVC doesn't support continuous values\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_frame = dd.read_csv(\"Stations_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Code</th>\n",
       "      <th>name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10002</td>\n",
       "      <td>Métro Charlevoix (Centre / Charlevoix)</td>\n",
       "      <td>45.478228</td>\n",
       "      <td>-73.569651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4000</td>\n",
       "      <td>Jeanne-d'Arc / Ontario</td>\n",
       "      <td>45.549598</td>\n",
       "      <td>-73.541874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4001</td>\n",
       "      <td>Graham / Brookfield</td>\n",
       "      <td>45.520075</td>\n",
       "      <td>-73.629776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4002</td>\n",
       "      <td>Graham / Wicksteed</td>\n",
       "      <td>45.516937</td>\n",
       "      <td>-73.640483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5002</td>\n",
       "      <td>St-Charles / Montarville</td>\n",
       "      <td>45.533682</td>\n",
       "      <td>-73.515261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Code                                    name   latitude  longitude\n",
       "0  10002  Métro Charlevoix (Centre / Charlevoix)  45.478228 -73.569651\n",
       "1   4000                  Jeanne-d'Arc / Ontario  45.549598 -73.541874\n",
       "2   4001                     Graham / Brookfield  45.520075 -73.629776\n",
       "3   4002                      Graham / Wicksteed  45.516937 -73.640483\n",
       "4   5002                St-Charles / Montarville  45.533682 -73.515261"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "montreal_boundaries = new_frame[(new_frame.latitude <= 45.5017) & (new_frame.longitude <= -73.5673 )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clustering\n",
    "coord = montreal_boundaries[[\"latitude\", \"longitude\"]].values\n",
    "neighbors = []\n",
    "\n",
    "def min_distance(regionCenters, totalClusters):\n",
    "    good_points = 0\n",
    "    bad_points = 0\n",
    "    less_dist = []\n",
    "    more_dist = []\n",
    "    min_distance = 100000  #any big number can be given here\n",
    "    for i in range(totalClusters):\n",
    "        good_points = 0\n",
    "        bad_points = 0\n",
    "        for j in range(totalClusters):\n",
    "            if j != i:\n",
    "                distance = gpxpy.geo.haversine_distance(latitude_1 = regionCenters[i][0], longitude_1 = regionCenters[i][1], latitude_2 = regionCenters[j][0], longitude_2 = regionCenters[j][1])\n",
    "                #you can check the documentation of above \"gpxpy.geo.haversine_distance\" at \"https://github.com/tkrajina/gpxpy/blob/master/gpxpy/geo.py\"\n",
    "                #\"gpxpy.geo.haversine_distance\" gives distance between two latitudes and longitudes in meters. So, we have to convert it into miles.\n",
    "                distance = distance/(1.60934*1000)   #distance from meters to miles\n",
    "                min_distance = min(min_distance, distance) #it will return minimum of \"min_distance, distance\".\n",
    "                if distance < 2:\n",
    "                    good_points += 1\n",
    "                else:\n",
    "                    bad_points += 1\n",
    "        less_dist.append(good_points)\n",
    "        more_dist.append(bad_points)\n",
    "    print(\"On choosing a cluster size of {}\".format(totalClusters))\n",
    "    print(\"Avg. Number clusters within vicinity where inter cluster distance < 2 miles is {}\".format(np.ceil(sum(less_dist)/len(less_dist))))\n",
    "    print(\"Avg. Number clusters outside of vicinity where inter cluster distance > 2 miles is {}\".format(np.ceil(sum(more_dist)/len(more_dist))))\n",
    "    print(\"Minimum distance between any two clusters = {}\".format(min_distance))\n",
    "    print(\"-\"*10)\n",
    "            \n",
    "def makingRegions(noOfRegions):\n",
    "    regions = MiniBatchKMeans(n_clusters = noOfRegions, batch_size = 10000).fit(coord)\n",
    "    regionCenters = regions.cluster_centers_ \n",
    "    totalClusters = len(regionCenters)\n",
    "    return regionCenters, totalClusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On choosing a cluster size of 10\n",
      "Avg. Number clusters within vicinity where inter cluster distance < 2 miles is 3.0\n",
      "Avg. Number clusters outside of vicinity where inter cluster distance > 2 miles is 7.0\n",
      "Minimum distance between any two clusters = 0.9661826309055204\n",
      "----------\n",
      "On choosing a cluster size of 20\n",
      "Avg. Number clusters within vicinity where inter cluster distance < 2 miles is 5.0\n",
      "Avg. Number clusters outside of vicinity where inter cluster distance > 2 miles is 15.0\n",
      "Minimum distance between any two clusters = 0.34593524207718\n",
      "----------\n",
      "On choosing a cluster size of 30\n",
      "Avg. Number clusters within vicinity where inter cluster distance < 2 miles is 8.0\n",
      "Avg. Number clusters outside of vicinity where inter cluster distance > 2 miles is 22.0\n",
      "Minimum distance between any two clusters = 0.3789738029262929\n",
      "----------\n",
      "On choosing a cluster size of 40\n",
      "Avg. Number clusters within vicinity where inter cluster distance < 2 miles is 12.0\n",
      "Avg. Number clusters outside of vicinity where inter cluster distance > 2 miles is 28.0\n",
      "Minimum distance between any two clusters = 0.26620036533168\n",
      "----------\n",
      "On choosing a cluster size of 50\n",
      "Avg. Number clusters within vicinity where inter cluster distance < 2 miles is 16.0\n",
      "Avg. Number clusters outside of vicinity where inter cluster distance > 2 miles is 34.0\n",
      "Minimum distance between any two clusters = 0.23040417505020458\n",
      "----------\n",
      "On choosing a cluster size of 60\n",
      "Avg. Number clusters within vicinity where inter cluster distance < 2 miles is 21.0\n",
      "Avg. Number clusters outside of vicinity where inter cluster distance > 2 miles is 39.0\n",
      "Minimum distance between any two clusters = 0.1875884491710632\n",
      "----------\n",
      "On choosing a cluster size of 70\n",
      "Avg. Number clusters within vicinity where inter cluster distance < 2 miles is 25.0\n",
      "Avg. Number clusters outside of vicinity where inter cluster distance > 2 miles is 45.0\n",
      "Minimum distance between any two clusters = 0.14914194000399938\n",
      "----------\n",
      "On choosing a cluster size of 80\n",
      "Avg. Number clusters within vicinity where inter cluster distance < 2 miles is 29.0\n",
      "Avg. Number clusters outside of vicinity where inter cluster distance > 2 miles is 51.0\n",
      "Minimum distance between any two clusters = 0.15836886519176066\n",
      "----------\n",
      "On choosing a cluster size of 90\n",
      "Avg. Number clusters within vicinity where inter cluster distance < 2 miles is 33.0\n",
      "Avg. Number clusters outside of vicinity where inter cluster distance > 2 miles is 57.0\n",
      "Minimum distance between any two clusters = 0.15402765429595153\n",
      "----------\n",
      "Time taken = 0:00:03.502676\n"
     ]
    }
   ],
   "source": [
    "startTime = datetime.now()\n",
    "for i in range(10, 100, 10):\n",
    "    regionCenters, totalClusters = makingRegions(i)\n",
    "    min_distance(regionCenters, totalClusters)\n",
    "print(\"Time taken = \"+str(datetime.now() - startTime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dask.array<values, shape=(nan, 2), dtype=float64, chunksize=(nan, 2), chunktype=numpy.ndarray>\n"
     ]
    }
   ],
   "source": [
    "#Mini Batch K-means model\n",
    "coord = montreal_boundaries[[\"latitude\", \"longitude\"]].values\n",
    "print(coord)\n",
    "regions = MiniBatchKMeans(n_clusters = 30, batch_size = 100000).fit(coord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewFrame = new_frame[['latitude','longitude', 'Code']].compute()\n",
    "NewFrame[\"pickup_cluster\"] = regions.predict(NewFrame[[\"latitude\", \"longitude\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    latitude  longitude   Code  pickup_cluster\n",
      "0  45.478228 -73.569651  10002              25\n",
      "1  45.549598 -73.541874   4000               8\n",
      "2  45.520075 -73.629776   4001               1\n",
      "3  45.516937 -73.640483   4002               1\n",
      "4  45.533682 -73.515261   5002               8\n",
      "(615, 4)\n"
     ]
    }
   ],
   "source": [
    "print(NewFrame.head())\n",
    "print (NewFrame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "NewFrame = NewFrame.sort_values(by=['pickup_cluster'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6436: 0,\n",
       " 6093: 0,\n",
       " 6433: 0,\n",
       " 6432: 0,\n",
       " 6194: 0,\n",
       " 6410: 1,\n",
       " 6737: 1,\n",
       " 7004: 1,\n",
       " 6312: 1,\n",
       " 6323: 1,\n",
       " 7064: 1,\n",
       " 6324: 1,\n",
       " 6330: 1,\n",
       " 6331: 1,\n",
       " 6332: 1,\n",
       " 6333: 1,\n",
       " 7148: 1,\n",
       " 7001: 1,\n",
       " 7063: 1,\n",
       " 6412: 1,\n",
       " 7007: 1,\n",
       " 6419: 1,\n",
       " 6240: 1,\n",
       " 4001: 1,\n",
       " 6125: 1,\n",
       " 7099: 1,\n",
       " 4002: 1,\n",
       " 6423: 1,\n",
       " 6717: 1,\n",
       " 6754: 2,\n",
       " 7051: 2,\n",
       " 6744: 2,\n",
       " 6742: 2,\n",
       " 6725: 2,\n",
       " 7048: 2,\n",
       " 7111: 3,\n",
       " 6719: 4,\n",
       " 6369: 4,\n",
       " 6705: 5,\n",
       " 6709: 5,\n",
       " 6707: 5,\n",
       " 6435: 6,\n",
       " 6080: 6,\n",
       " 6434: 6,\n",
       " 6101: 7,\n",
       " 6339: 7,\n",
       " 6356: 7,\n",
       " 6383: 8,\n",
       " 6381: 8,\n",
       " 6386: 8,\n",
       " 6380: 8,\n",
       " 6376: 8,\n",
       " 6384: 8,\n",
       " 6385: 8,\n",
       " 6417: 8,\n",
       " 6388: 8,\n",
       " 6391: 8,\n",
       " 6424: 8,\n",
       " 6393: 8,\n",
       " 6394: 8,\n",
       " 6395: 8,\n",
       " 6396: 8,\n",
       " 6397: 8,\n",
       " 6398: 8,\n",
       " 6411: 8,\n",
       " 6413: 8,\n",
       " 6387: 8,\n",
       " 6421: 8,\n",
       " 6346: 8,\n",
       " 6373: 8,\n",
       " 6264: 8,\n",
       " 6261: 8,\n",
       " 6260: 8,\n",
       " 6259: 8,\n",
       " 6258: 8,\n",
       " 6248: 8,\n",
       " 6237: 8,\n",
       " 6236: 8,\n",
       " 6229: 8,\n",
       " 6226: 8,\n",
       " 6221: 8,\n",
       " 6220: 8,\n",
       " 6219: 8,\n",
       " 6218: 8,\n",
       " 6217: 8,\n",
       " 6216: 8,\n",
       " 6215: 8,\n",
       " 6214: 8,\n",
       " 6213: 8,\n",
       " 6265: 8,\n",
       " 6374: 8,\n",
       " 6266: 8,\n",
       " 6269: 8,\n",
       " 6372: 8,\n",
       " 6371: 8,\n",
       " 6370: 8,\n",
       " 6368: 8,\n",
       " 6367: 8,\n",
       " 6364: 8,\n",
       " 6362: 8,\n",
       " 6360: 8,\n",
       " 6359: 8,\n",
       " 6358: 8,\n",
       " 6357: 8,\n",
       " 6355: 8,\n",
       " 6314: 8,\n",
       " 6307: 8,\n",
       " 6281: 8,\n",
       " 6278: 8,\n",
       " 6277: 8,\n",
       " 6274: 8,\n",
       " 6271: 8,\n",
       " 6267: 8,\n",
       " 6361: 8,\n",
       " 6713: 8,\n",
       " 6502: 8,\n",
       " 7080: 8,\n",
       " 7079: 8,\n",
       " 7078: 8,\n",
       " 7077: 8,\n",
       " 7075: 8,\n",
       " 7074: 8,\n",
       " 7073: 8,\n",
       " 7072: 8,\n",
       " 7081: 8,\n",
       " 7069: 8,\n",
       " 7066: 8,\n",
       " 7062: 8,\n",
       " 7047: 8,\n",
       " 7046: 8,\n",
       " 7044: 8,\n",
       " 7043: 8,\n",
       " 7041: 8,\n",
       " 7039: 8,\n",
       " 7067: 8,\n",
       " 7083: 8,\n",
       " 7084: 8,\n",
       " 7085: 8,\n",
       " 7146: 8,\n",
       " 7139: 8,\n",
       " 7138: 8,\n",
       " 7137: 8,\n",
       " 7126: 8,\n",
       " 7125: 8,\n",
       " 7121: 8,\n",
       " 7120: 8,\n",
       " 7119: 8,\n",
       " 7118: 8,\n",
       " 7117: 8,\n",
       " 7116: 8,\n",
       " 7115: 8,\n",
       " 7098: 8,\n",
       " 7097: 8,\n",
       " 7089: 8,\n",
       " 7088: 8,\n",
       " 7087: 8,\n",
       " 7086: 8,\n",
       " 7038: 8,\n",
       " 6501: 8,\n",
       " 7037: 8,\n",
       " 7033: 8,\n",
       " 6750: 8,\n",
       " 6749: 8,\n",
       " 6739: 8,\n",
       " 6738: 8,\n",
       " 6731: 8,\n",
       " 6730: 8,\n",
       " 6729: 8,\n",
       " 6723: 8,\n",
       " 6753: 8,\n",
       " 6722: 8,\n",
       " 6720: 8,\n",
       " 6212: 8,\n",
       " 6704: 8,\n",
       " 6703: 8,\n",
       " 6702: 8,\n",
       " 6701: 8,\n",
       " 6700: 8,\n",
       " 6504: 8,\n",
       " 6721: 8,\n",
       " 6901: 8,\n",
       " 6902: 8,\n",
       " 6903: 8,\n",
       " 7032: 8,\n",
       " 7031: 8,\n",
       " 7030: 8,\n",
       " 7029: 8,\n",
       " 7027: 8,\n",
       " 7024: 8,\n",
       " 7020: 8,\n",
       " 7018: 8,\n",
       " 7017: 8,\n",
       " 7016: 8,\n",
       " 7012: 8,\n",
       " 7011: 8,\n",
       " 7009: 8,\n",
       " 6929: 8,\n",
       " 6926: 8,\n",
       " 6919: 8,\n",
       " 6918: 8,\n",
       " 6916: 8,\n",
       " 6905: 8,\n",
       " 7035: 8,\n",
       " 6211: 8,\n",
       " 7149: 8,\n",
       " 6209: 8,\n",
       " 6116: 8,\n",
       " 6114: 8,\n",
       " 6113: 8,\n",
       " 6112: 8,\n",
       " 6111: 8,\n",
       " 6110: 8,\n",
       " 6109: 8,\n",
       " 6108: 8,\n",
       " 6106: 8,\n",
       " 6105: 8,\n",
       " 6104: 8,\n",
       " 6103: 8,\n",
       " 6117: 8,\n",
       " 6096: 8,\n",
       " 6090: 8,\n",
       " 6087: 8,\n",
       " 6085: 8,\n",
       " 6084: 8,\n",
       " 6083: 8,\n",
       " 6082: 8,\n",
       " 6079: 8,\n",
       " 6078: 8,\n",
       " 6076: 8,\n",
       " 6075: 8,\n",
       " 6073: 8,\n",
       " 6072: 8,\n",
       " 6092: 8,\n",
       " 6118: 8,\n",
       " 6119: 8,\n",
       " 6120: 8,\n",
       " 6151: 8,\n",
       " 6150: 8,\n",
       " 6149: 8,\n",
       " 6148: 8,\n",
       " 6147: 8,\n",
       " 6146: 8,\n",
       " 6145: 8,\n",
       " 6143: 8,\n",
       " 6142: 8,\n",
       " 6141: 8,\n",
       " 6140: 8,\n",
       " 6139: 8,\n",
       " 6138: 8,\n",
       " 6137: 8,\n",
       " 6136: 8,\n",
       " 6134: 8,\n",
       " 6133: 8,\n",
       " 6132: 8,\n",
       " 6131: 8,\n",
       " 6130: 8,\n",
       " 6129: 8,\n",
       " 6128: 8,\n",
       " 6126: 8,\n",
       " 6124: 8,\n",
       " 6123: 8,\n",
       " 6122: 8,\n",
       " 6121: 8,\n",
       " 6070: 8,\n",
       " 6152: 8,\n",
       " 6067: 8,\n",
       " 6063: 8,\n",
       " 6022: 8,\n",
       " 6021: 8,\n",
       " 6020: 8,\n",
       " 6019: 8,\n",
       " 6018: 8,\n",
       " 6017: 8,\n",
       " 6015: 8,\n",
       " 6014: 8,\n",
       " 6013: 8,\n",
       " 6012: 8,\n",
       " 6011: 8,\n",
       " 6008: 8,\n",
       " 6023: 8,\n",
       " 6007: 8,\n",
       " 6005: 8,\n",
       " 6004: 8,\n",
       " 6003: 8,\n",
       " 6002: 8,\n",
       " 6001: 8,\n",
       " 5007: 8,\n",
       " 5006: 8,\n",
       " 5005: 8,\n",
       " 5004: 8,\n",
       " 5003: 8,\n",
       " 5002: 8,\n",
       " 4000: 8,\n",
       " 6006: 8,\n",
       " 6024: 8,\n",
       " 6025: 8,\n",
       " 6026: 8,\n",
       " 6062: 8,\n",
       " 6061: 8,\n",
       " 6060: 8,\n",
       " 6059: 8,\n",
       " 6058: 8,\n",
       " 6057: 8,\n",
       " 6053: 8,\n",
       " 6052: 8,\n",
       " 6050: 8,\n",
       " 6049: 8,\n",
       " 6048: 8,\n",
       " 6047: 8,\n",
       " 6046: 8,\n",
       " 6044: 8,\n",
       " 6043: 8,\n",
       " 6042: 8,\n",
       " 6041: 8,\n",
       " 6040: 8,\n",
       " 6039: 8,\n",
       " 6038: 8,\n",
       " 6037: 8,\n",
       " 6036: 8,\n",
       " 6035: 8,\n",
       " 6033: 8,\n",
       " 6032: 8,\n",
       " 6031: 8,\n",
       " 6027: 8,\n",
       " 6064: 8,\n",
       " 6153: 8,\n",
       " 6099: 8,\n",
       " 6155: 8,\n",
       " 6186: 8,\n",
       " 6177: 8,\n",
       " 6167: 8,\n",
       " 6184: 8,\n",
       " 6183: 8,\n",
       " 6197: 8,\n",
       " 6169: 8,\n",
       " 6170: 8,\n",
       " 6171: 8,\n",
       " 6182: 8,\n",
       " 6187: 8,\n",
       " 6179: 8,\n",
       " 6174: 8,\n",
       " 6204: 8,\n",
       " 6203: 8,\n",
       " 6175: 8,\n",
       " 6181: 8,\n",
       " 6180: 8,\n",
       " 6202: 8,\n",
       " 6201: 8,\n",
       " 6192: 8,\n",
       " 6176: 8,\n",
       " 6173: 8,\n",
       " 6178: 8,\n",
       " 6154: 8,\n",
       " 6164: 8,\n",
       " 6157: 8,\n",
       " 6163: 8,\n",
       " 6207: 8,\n",
       " 6156: 8,\n",
       " 6161: 8,\n",
       " 6160: 8,\n",
       " 6206: 8,\n",
       " 6190: 8,\n",
       " 6188: 8,\n",
       " 6166: 8,\n",
       " 6208: 8,\n",
       " 6159: 8,\n",
       " 6158: 8,\n",
       " 6205: 8,\n",
       " 6165: 8,\n",
       " 7105: 9,\n",
       " 6409: 10,\n",
       " 6408: 10,\n",
       " 6407: 10,\n",
       " 7140: 10,\n",
       " 6405: 10,\n",
       " 6404: 10,\n",
       " 7112: 11,\n",
       " 7109: 11,\n",
       " 7060: 12,\n",
       " 7142: 12,\n",
       " 6425: 12,\n",
       " 7058: 12,\n",
       " 6341: 12,\n",
       " 7057: 12,\n",
       " 6309: 12,\n",
       " 6379: 12,\n",
       " 6426: 12,\n",
       " 7144: 12,\n",
       " 6427: 12,\n",
       " 6428: 12,\n",
       " 6429: 12,\n",
       " 7110: 13,\n",
       " 7015: 14,\n",
       " 7108: 14,\n",
       " 6243: 15,\n",
       " 6930: 15,\n",
       " 7065: 15,\n",
       " 6068: 15,\n",
       " 6906: 15,\n",
       " 6913: 15,\n",
       " 6927: 15,\n",
       " 6925: 15,\n",
       " 6924: 15,\n",
       " 6923: 15,\n",
       " 6908: 15,\n",
       " 6247: 15,\n",
       " 6276: 15,\n",
       " 6246: 15,\n",
       " 6910: 15,\n",
       " 6912: 15,\n",
       " 6245: 15,\n",
       " 6915: 15,\n",
       " 6928: 15,\n",
       " 6279: 15,\n",
       " 7021: 15,\n",
       " 6250: 15,\n",
       " 6257: 15,\n",
       " 6191: 15,\n",
       " 7042: 15,\n",
       " 7040: 15,\n",
       " 6189: 15,\n",
       " 6262: 15,\n",
       " 6254: 15,\n",
       " 6253: 15,\n",
       " 6252: 15,\n",
       " 6051: 15,\n",
       " 6185: 15,\n",
       " 6268: 15,\n",
       " 7025: 15,\n",
       " 7023: 15,\n",
       " 7022: 15,\n",
       " 6301: 15,\n",
       " 6270: 15,\n",
       " 7019: 15,\n",
       " 6272: 15,\n",
       " 6273: 15,\n",
       " 7014: 15,\n",
       " 6275: 15,\n",
       " 7061: 15,\n",
       " 6251: 15,\n",
       " 7008: 15,\n",
       " 6249: 15,\n",
       " 6904: 15,\n",
       " 6310: 15,\n",
       " 6235: 15,\n",
       " 6302: 15,\n",
       " 6315: 15,\n",
       " 6316: 15,\n",
       " 6321: 15,\n",
       " 6322: 15,\n",
       " 6327: 15,\n",
       " 6503: 15,\n",
       " 6328: 15,\n",
       " 7127: 15,\n",
       " 6329: 15,\n",
       " 6168: 15,\n",
       " 6711: 15,\n",
       " 6334: 15,\n",
       " 6336: 15,\n",
       " 6338: 15,\n",
       " 6127: 15,\n",
       " 6340: 15,\n",
       " 6343: 15,\n",
       " 6344: 15,\n",
       " 6345: 15,\n",
       " 6347: 15,\n",
       " 6389: 15,\n",
       " 7147: 15,\n",
       " 6366: 15,\n",
       " 6335: 15,\n",
       " 6199: 15,\n",
       " 7124: 15,\n",
       " 6232: 15,\n",
       " 6303: 15,\n",
       " 6304: 15,\n",
       " 6305: 15,\n",
       " 6752: 15,\n",
       " 6306: 15,\n",
       " 6234: 15,\n",
       " 6233: 15,\n",
       " 6747: 15,\n",
       " 6746: 15,\n",
       " 6745: 15,\n",
       " 6231: 15,\n",
       " 6230: 15,\n",
       " 6228: 15,\n",
       " 6255: 15,\n",
       " 6735: 15,\n",
       " 6734: 15,\n",
       " 6733: 15,\n",
       " 6311: 15,\n",
       " 6728: 15,\n",
       " 7045: 15,\n",
       " 7122: 16,\n",
       " 7123: 16,\n",
       " 7095: 16,\n",
       " 7094: 16,\n",
       " 7136: 16,\n",
       " 7135: 16,\n",
       " 7134: 16,\n",
       " 7092: 16,\n",
       " 7090: 16,\n",
       " 7133: 16,\n",
       " 7132: 16,\n",
       " 7131: 16,\n",
       " 7130: 16,\n",
       " 7091: 16,\n",
       " 7129: 16,\n",
       " 7096: 16,\n",
       " 7128: 16,\n",
       " 7093: 16,\n",
       " 7101: 16,\n",
       " 7005: 16,\n",
       " 6710: 16,\n",
       " 6726: 16,\n",
       " 7002: 16,\n",
       " 6716: 16,\n",
       " 6162: 16,\n",
       " 7006: 16,\n",
       " 6917: 16,\n",
       " 6210: 16,\n",
       " 6736: 16,\n",
       " 6422: 16,\n",
       " 6313: 17,\n",
       " 6724: 17,\n",
       " 7054: 17,\n",
       " 6402: 17,\n",
       " 6375: 17,\n",
       " 7010: 18,\n",
       " 6420: 18,\n",
       " 6089: 19,\n",
       " 6222: 19,\n",
       " 6200: 19,\n",
       " 6223: 19,\n",
       " 6094: 19,\n",
       " 6091: 19,\n",
       " 6009: 19,\n",
       " 6224: 19,\n",
       " 6227: 19,\n",
       " 7036: 19,\n",
       " 6198: 19,\n",
       " 7113: 19,\n",
       " 6097: 19,\n",
       " 6098: 19,\n",
       " 6225: 19,\n",
       " 6102: 19,\n",
       " 6095: 19,\n",
       " 6743: 19,\n",
       " 6195: 19,\n",
       " 7003: 19,\n",
       " 7028: 19,\n",
       " 7026: 19,\n",
       " 6065: 19,\n",
       " 6066: 19,\n",
       " 6107: 19,\n",
       " 7071: 19,\n",
       " 6100: 19,\n",
       " 6907: 19,\n",
       " 6081: 19,\n",
       " 6280: 19,\n",
       " 6193: 19,\n",
       " 7076: 19,\n",
       " 6196: 19,\n",
       " 6241: 19,\n",
       " 7059: 20,\n",
       " 6706: 20,\n",
       " 7056: 20,\n",
       " 7143: 20,\n",
       " 7145: 20,\n",
       " 6715: 20,\n",
       " 7103: 21,\n",
       " 7104: 21,\n",
       " 6714: 22,\n",
       " 6115: 23,\n",
       " 6718: 23,\n",
       " 6263: 23,\n",
       " 7102: 23,\n",
       " 7013: 23,\n",
       " 6712: 24,\n",
       " 10002: 25,\n",
       " 6401: 25,\n",
       " 6349: 25,\n",
       " 6350: 25,\n",
       " 7052: 25,\n",
       " 6921: 25,\n",
       " 7068: 25,\n",
       " 6377: 25,\n",
       " 7070: 25,\n",
       " 6086: 25,\n",
       " 7050: 25,\n",
       " 6748: 25,\n",
       " 6016: 25,\n",
       " 6088: 25,\n",
       " 6741: 25,\n",
       " 6732: 25,\n",
       " 6727: 25,\n",
       " 7114: 25,\n",
       " 7049: 25,\n",
       " 7053: 25,\n",
       " 6403: 25,\n",
       " 6418: 26,\n",
       " 7100: 26,\n",
       " 7107: 27,\n",
       " 7106: 27,\n",
       " 6414: 28,\n",
       " 7141: 28,\n",
       " 7055: 28,\n",
       " 7034: 28,\n",
       " 6029: 28,\n",
       " 7082: 28,\n",
       " 6406: 28,\n",
       " 6415: 29,\n",
       " 6416: 29,\n",
       " 6354: 29,\n",
       " 6363: 29}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict = dict(zip(NewFrame.Code, NewFrame.pickup_cluster))\n",
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              start_date  start_station_code          end_date  \\\n",
      "849566  2018-07-28 22:03                4000  2018-07-28 22:43   \n",
      "784874  2018-07-26 21:28                4000  2018-07-26 21:56   \n",
      "795083  2018-07-27 09:25                4000  2018-07-27 09:30   \n",
      "768486  2018-07-26 14:35                4000  2018-07-26 15:05   \n",
      "556753  2018-07-18 19:24                4000  2018-07-18 19:34   \n",
      "\n",
      "        end_station_code  duration_sec  is_member  \n",
      "849566              6111          2350          1  \n",
      "784874              7067          1673          1  \n",
      "795083              6391           303          1  \n",
      "768486              7031          1805          0  \n",
      "556753              6701           570          0  \n",
      "(953031, 6)\n"
     ]
    }
   ],
   "source": [
    "bike_data_frame = pd.read_csv(\"OD_2018-07.csv\")\n",
    "bike_data_frame = bike_data_frame.sort_values(by=['start_station_code'])\n",
    "print(bike_data_frame.head())\n",
    "print (bike_data_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data_frame['pickup_cluster'] = bike_data_frame['start_station_code']\\\n",
    "                               .map(mydict) \n",
    "bike_data_frame['dropoff_cluster'] = bike_data_frame['end_station_code']\\\n",
    "                               .map(mydict) \\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_station_code</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_station_code</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>is_member</th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>dropoff_cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849566</th>\n",
       "      <td>2018-07-28 22:03</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-28 22:43</td>\n",
       "      <td>6111</td>\n",
       "      <td>2350</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784874</th>\n",
       "      <td>2018-07-26 21:28</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-26 21:56</td>\n",
       "      <td>7067</td>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795083</th>\n",
       "      <td>2018-07-27 09:25</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-27 09:30</td>\n",
       "      <td>6391</td>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768486</th>\n",
       "      <td>2018-07-26 14:35</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-26 15:05</td>\n",
       "      <td>7031</td>\n",
       "      <td>1805</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556753</th>\n",
       "      <td>2018-07-18 19:24</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-18 19:34</td>\n",
       "      <td>6701</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              start_date  start_station_code          end_date  \\\n",
       "849566  2018-07-28 22:03                4000  2018-07-28 22:43   \n",
       "784874  2018-07-26 21:28                4000  2018-07-26 21:56   \n",
       "795083  2018-07-27 09:25                4000  2018-07-27 09:30   \n",
       "768486  2018-07-26 14:35                4000  2018-07-26 15:05   \n",
       "556753  2018-07-18 19:24                4000  2018-07-18 19:34   \n",
       "\n",
       "        end_station_code  duration_sec  is_member  pickup_cluster  \\\n",
       "849566              6111          2350          1             8.0   \n",
       "784874              7067          1673          1             8.0   \n",
       "795083              6391           303          1             8.0   \n",
       "768486              7031          1805          0             8.0   \n",
       "556753              6701           570          0             8.0   \n",
       "\n",
       "        dropoff_cluster  \n",
       "849566              8.0  \n",
       "784874              8.0  \n",
       "795083              8.0  \n",
       "768486              8.0  \n",
       "556753              8.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_station_code</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_station_code</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>is_member</th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>dropoff_cluster</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_weekday</th>\n",
       "      <th>end_hour</th>\n",
       "      <th>end_weekday</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849566</th>\n",
       "      <td>2018-07-28 22:03:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-28 22:43:00+00:00</td>\n",
       "      <td>6111</td>\n",
       "      <td>2350</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784874</th>\n",
       "      <td>2018-07-26 21:28:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-26 21:56:00+00:00</td>\n",
       "      <td>7067</td>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795083</th>\n",
       "      <td>2018-07-27 09:25:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-27 09:30:00+00:00</td>\n",
       "      <td>6391</td>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768486</th>\n",
       "      <td>2018-07-26 14:35:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-26 15:05:00+00:00</td>\n",
       "      <td>7031</td>\n",
       "      <td>1805</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556753</th>\n",
       "      <td>2018-07-18 19:24:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-18 19:34:00+00:00</td>\n",
       "      <td>6701</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      start_date  start_station_code  \\\n",
       "849566 2018-07-28 22:03:00+00:00                4000   \n",
       "784874 2018-07-26 21:28:00+00:00                4000   \n",
       "795083 2018-07-27 09:25:00+00:00                4000   \n",
       "768486 2018-07-26 14:35:00+00:00                4000   \n",
       "556753 2018-07-18 19:24:00+00:00                4000   \n",
       "\n",
       "                        end_date  end_station_code  duration_sec  is_member  \\\n",
       "849566 2018-07-28 22:43:00+00:00              6111          2350          1   \n",
       "784874 2018-07-26 21:56:00+00:00              7067          1673          1   \n",
       "795083 2018-07-27 09:30:00+00:00              6391           303          1   \n",
       "768486 2018-07-26 15:05:00+00:00              7031          1805          0   \n",
       "556753 2018-07-18 19:34:00+00:00              6701           570          0   \n",
       "\n",
       "        pickup_cluster  dropoff_cluster  start_hour  start_weekday  end_hour  \\\n",
       "849566             8.0              8.0          22              5        22   \n",
       "784874             8.0              8.0          21              3        21   \n",
       "795083             8.0              8.0           9              4         9   \n",
       "768486             8.0              8.0          14              3        15   \n",
       "556753             8.0              8.0          19              2        19   \n",
       "\n",
       "        end_weekday  day_of_month  \n",
       "849566            5            28  \n",
       "784874            3            26  \n",
       "795083            4            27  \n",
       "768486            3            26  \n",
       "556753            2            18  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature engineer the hour and weekday of the start time and end time \n",
    "bike_data_frame['start_date'] = pd.to_datetime(bike_data_frame['start_date'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "bike_data_frame['end_date'] = pd.to_datetime(bike_data_frame['end_date'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "bike_data_frame['start_hour'] = bike_data_frame['start_date'].dt.hour\n",
    "bike_data_frame['start_weekday'] = bike_data_frame['start_date'].dt.weekday\n",
    "bike_data_frame['end_hour'] = bike_data_frame['end_date'].dt.hour\n",
    "bike_data_frame['end_weekday'] = bike_data_frame['end_date'].dt.weekday\n",
    "bike_data_frame['day_of_month'] = bike_data_frame['start_date'].dt.day\n",
    "bike_data_frame.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_station_code</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_station_code</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>is_member</th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>dropoff_cluster</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_weekday</th>\n",
       "      <th>end_hour</th>\n",
       "      <th>end_weekday</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849566</th>\n",
       "      <td>2018-07-28 22:03:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-28 22:43:00+00:00</td>\n",
       "      <td>6111</td>\n",
       "      <td>2350</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784874</th>\n",
       "      <td>2018-07-26 21:28:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-26 21:56:00+00:00</td>\n",
       "      <td>7067</td>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795083</th>\n",
       "      <td>2018-07-27 09:25:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-27 09:30:00+00:00</td>\n",
       "      <td>6391</td>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768486</th>\n",
       "      <td>2018-07-26 14:35:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-26 15:05:00+00:00</td>\n",
       "      <td>7031</td>\n",
       "      <td>1805</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556753</th>\n",
       "      <td>2018-07-18 19:24:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-18 19:34:00+00:00</td>\n",
       "      <td>6701</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      start_date  start_station_code  \\\n",
       "849566 2018-07-28 22:03:00+00:00                4000   \n",
       "784874 2018-07-26 21:28:00+00:00                4000   \n",
       "795083 2018-07-27 09:25:00+00:00                4000   \n",
       "768486 2018-07-26 14:35:00+00:00                4000   \n",
       "556753 2018-07-18 19:24:00+00:00                4000   \n",
       "\n",
       "                        end_date  end_station_code  duration_sec  is_member  \\\n",
       "849566 2018-07-28 22:43:00+00:00              6111          2350          1   \n",
       "784874 2018-07-26 21:56:00+00:00              7067          1673          1   \n",
       "795083 2018-07-27 09:30:00+00:00              6391           303          1   \n",
       "768486 2018-07-26 15:05:00+00:00              7031          1805          0   \n",
       "556753 2018-07-18 19:34:00+00:00              6701           570          0   \n",
       "\n",
       "        pickup_cluster  dropoff_cluster  start_hour  start_weekday  end_hour  \\\n",
       "849566             8.0              8.0          22              5        22   \n",
       "784874             8.0              8.0          21              3        21   \n",
       "795083             8.0              8.0           9              4         9   \n",
       "768486             8.0              8.0          14              3        15   \n",
       "556753             8.0              8.0          19              2        19   \n",
       "\n",
       "        end_weekday  day_of_month  \n",
       "849566            5            28  \n",
       "784874            3            26  \n",
       "795083            4            27  \n",
       "768486            3            26  \n",
       "556753            2            18  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data filtering \n",
    "bike_data_frame = bike_data_frame[(bike_data_frame.start_hour>4) & (bike_data_frame.start_hour<24)]\n",
    "bike_data_frame = bike_data_frame[(bike_data_frame.end_hour>4) & (bike_data_frame.end_hour<24)]\n",
    "bike_data_frame = bike_data_frame[(bike_data_frame.duration_sec>0) & (bike_data_frame.duration_sec<7000)]\n",
    "#bike_data_frame = bike_data_frame.drop(['start_date', 'end_date', 'is_member'], axis=1)\n",
    "\n",
    "bike_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_station_code</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_station_code</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>is_member</th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>dropoff_cluster</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_weekday</th>\n",
       "      <th>end_hour</th>\n",
       "      <th>end_weekday</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "      <th>pcluster</th>\n",
       "      <th>dcluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204390</th>\n",
       "      <td>2018-07-07 22:36:00+00:00</td>\n",
       "      <td>10002</td>\n",
       "      <td>2018-07-07 22:38:00+00:00</td>\n",
       "      <td>6349</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>546</td>\n",
       "      <td>306</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866649</th>\n",
       "      <td>2018-07-29 14:40:00+00:00</td>\n",
       "      <td>10002</td>\n",
       "      <td>2018-07-29 14:59:00+00:00</td>\n",
       "      <td>6159</td>\n",
       "      <td>1154</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>546</td>\n",
       "      <td>152</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236630</th>\n",
       "      <td>2018-07-09 07:45:00+00:00</td>\n",
       "      <td>10002</td>\n",
       "      <td>2018-07-09 07:49:00+00:00</td>\n",
       "      <td>6921</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>546</td>\n",
       "      <td>454</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694073</th>\n",
       "      <td>2018-07-23 12:20:00+00:00</td>\n",
       "      <td>10002</td>\n",
       "      <td>2018-07-23 12:40:00+00:00</td>\n",
       "      <td>6052</td>\n",
       "      <td>1249</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>546</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332334</th>\n",
       "      <td>2018-07-11 21:45:00+00:00</td>\n",
       "      <td>10002</td>\n",
       "      <td>2018-07-11 21:51:00+00:00</td>\n",
       "      <td>6727</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>546</td>\n",
       "      <td>413</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      start_date  start_station_code  \\\n",
       "204390 2018-07-07 22:36:00+00:00               10002   \n",
       "866649 2018-07-29 14:40:00+00:00               10002   \n",
       "236630 2018-07-09 07:45:00+00:00               10002   \n",
       "694073 2018-07-23 12:20:00+00:00               10002   \n",
       "332334 2018-07-11 21:45:00+00:00               10002   \n",
       "\n",
       "                        end_date  end_station_code  duration_sec  is_member  \\\n",
       "204390 2018-07-07 22:38:00+00:00              6349           160          1   \n",
       "866649 2018-07-29 14:59:00+00:00              6159          1154          0   \n",
       "236630 2018-07-09 07:49:00+00:00              6921           285          1   \n",
       "694073 2018-07-23 12:40:00+00:00              6052          1249          0   \n",
       "332334 2018-07-11 21:51:00+00:00              6727           370          1   \n",
       "\n",
       "        pickup_cluster  dropoff_cluster  start_hour  start_weekday  end_hour  \\\n",
       "204390            25.0             25.0          22              5        22   \n",
       "866649            25.0              8.0          14              6        14   \n",
       "236630            25.0             25.0           7              0         7   \n",
       "694073            25.0              8.0          12              0        12   \n",
       "332334            25.0             25.0          21              2        21   \n",
       "\n",
       "        end_weekday  day_of_month  start_loc  end_loc  pcluster  dcluster  \n",
       "204390            5             7        546      306         3         3  \n",
       "866649            6            29        546      152         3         0  \n",
       "236630            0             9        546      454         3         3  \n",
       "694073            0            23        546       56         3         0  \n",
       "332334            2            11        546      413         3         3  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_loc = (bike_data_frame['start_station_code'].unique())\n",
    "start_loc_mapping = dict(zip(start_loc, \n",
    "                                 range(0, len(start_loc) + 1)))\n",
    "\n",
    "bike_data_frame['start_loc'] = bike_data_frame['start_station_code']\\\n",
    "                               .map(start_loc_mapping) \\\n",
    "                               .astype(int)\n",
    "bike_data_frame['end_loc'] = bike_data_frame['end_station_code'] \\\n",
    "                               .map(start_loc_mapping) \\\n",
    "                               .astype(int)\n",
    "\n",
    "pickup_cluster = (bike_data_frame['pickup_cluster'].unique())\n",
    "cluster_mapping = dict(zip(pickup_cluster, \n",
    "                                 range(0, len(pickup_cluster)+1 )))\n",
    "\n",
    "bike_data_frame['pcluster'] = bike_data_frame['pickup_cluster']\\\n",
    "                               .map(cluster_mapping ) \\\n",
    "                               .astype(int)\n",
    "bike_data_frame['dcluster'] = bike_data_frame['dropoff_cluster'] \\\n",
    "                               .map(cluster_mapping ) \\\n",
    "                               .astype(int)\n",
    "bike_data_frame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bike_data_frame.to_csv('bike_df_cluster.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: Cluster Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_ID = []\n",
    "gain_list = []\n",
    "cluster_ID = []\n",
    "day_of_month = []\n",
    "hour_of_day = []\n",
    "\n",
    "for i in range(0,32): # days of month 0-31\n",
    "    for j in range(5,24): # hours of day 5 am - 11 pm\n",
    "      #  for z in range(1,31): # pickup cluster 1 to 30\n",
    "                new_frame = bike_data_frame[bike_data_frame['day_of_month'] == i]\n",
    "                new_frame = new_frame[new_frame['start_hour'] == j]\n",
    "              #  new_frame = new_frame[new_frame['pickup_cluster'] == z]\n",
    "\n",
    "                n_gain = new_frame['pcluster'].value_counts(dropna=True, sort=True) #count unique values on the same row\n",
    "                n_gain = -1*n_gain      \n",
    "                p_gain = new_frame['dcluster'].value_counts(dropna=True, sort=True) \n",
    "                gain = pd.concat([p_gain, n_gain], axis=1)\n",
    "                gain = gain.replace(np.nan, 0)\n",
    "                tot_gain = gain['pcluster'] + gain['dcluster']\n",
    "                tot_gain_ind = tot_gain.index.values\n",
    "\n",
    "\n",
    "                for x in range(0,len(tot_gain)):\n",
    "                   cluster_ID.append(tot_gain_ind[x])\n",
    "                   gain_list.append(tot_gain.iloc[x])\n",
    "                   day_of_month.append(i)\n",
    "                   hour_of_day.append(j)\n",
    "                #   cluster.append(z)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>gain</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>hour_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8089</th>\n",
       "      <td>0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8064</th>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8039</th>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8014</th>\n",
       "      <td>0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7989</th>\n",
       "      <td>0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>18</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7963</th>\n",
       "      <td>0</td>\n",
       "      <td>305.0</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7938</th>\n",
       "      <td>0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>18</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7912</th>\n",
       "      <td>0</td>\n",
       "      <td>395.0</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7886</th>\n",
       "      <td>0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>18</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7867</th>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7844</th>\n",
       "      <td>0</td>\n",
       "      <td>-30.0</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7820</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7795</th>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>17</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7770</th>\n",
       "      <td>0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>17</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7744</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>17</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7719</th>\n",
       "      <td>0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7694</th>\n",
       "      <td>0</td>\n",
       "      <td>-80.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7669</th>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7644</th>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7619</th>\n",
       "      <td>0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8114</th>\n",
       "      <td>0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7594</th>\n",
       "      <td>0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8140</th>\n",
       "      <td>0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8192</th>\n",
       "      <td>0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8682</th>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8657</th>\n",
       "      <td>0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8996</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4883</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8707</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>25</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8732</th>\n",
       "      <td>25</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4857</th>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11934</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8757</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13587</th>\n",
       "      <td>25</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>30</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9022</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11908</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13958</th>\n",
       "      <td>25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>25</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11883</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4762</th>\n",
       "      <td>25</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11858</th>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4737</th>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8946</th>\n",
       "      <td>25</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>20</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>25</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11832</th>\n",
       "      <td>25</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>26</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11806</th>\n",
       "      <td>25</td>\n",
       "      <td>2.0</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>25</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>25</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14286 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cluster_id   gain  day_of_month  hour_of_day\n",
       "0               0    8.0             1            5\n",
       "8089            0   88.0            18           14\n",
       "843             0   45.0             2           21\n",
       "8064            0   55.0            18           13\n",
       "8039            0   89.0            18           12\n",
       "8014            0   92.0            18           11\n",
       "7989            0  148.0            18           10\n",
       "7963            0  305.0            18            9\n",
       "7938            0  767.0            18            8\n",
       "7912            0  395.0            18            7\n",
       "7886            0   97.0            18            6\n",
       "867             0   12.0             2           22\n",
       "7867            0   32.0            18            5\n",
       "7844            0  -30.0            17           23\n",
       "7820            0    5.0            17           22\n",
       "7795            0   43.0            17           21\n",
       "7770            0  111.0            17           20\n",
       "7744            0   79.0            17           19\n",
       "889             0    1.0             2           23\n",
       "7719            0   67.0            17           18\n",
       "7694            0  -80.0            17           17\n",
       "7669            0   33.0            17           16\n",
       "7644            0   13.0            17           15\n",
       "7619            0   69.0            17           14\n",
       "8114            0   82.0            18           15\n",
       "7594            0   94.0            17           13\n",
       "8140            0  -23.0            18           16\n",
       "8192            0   65.0            18           18\n",
       "8682            0   47.0            19           19\n",
       "8657            0   55.0            19           18\n",
       "...           ...    ...           ...          ...\n",
       "2057           25    0.0             5           13\n",
       "9358           25    0.0            21            8\n",
       "716            25    0.0             2           15\n",
       "8996           25    1.0            20           12\n",
       "2971           25    1.0             7           13\n",
       "4883           25    1.0            11           15\n",
       "2997           25    0.0             7           14\n",
       "8707           25    1.0            19           19\n",
       "313            25   -2.0             1           17\n",
       "8732           25   -3.0            19           20\n",
       "4857           25    3.0            11           14\n",
       "11934          25    0.0            26           21\n",
       "1863           25    1.0             5            5\n",
       "8757           25    0.0            19           21\n",
       "13587          25   -4.0            30           14\n",
       "9022           25    1.0            20           13\n",
       "1273           25    0.0             3           19\n",
       "11908          25    1.0            26           20\n",
       "13958          25    1.0            31           10\n",
       "3048           25   -3.0             7           16\n",
       "11883          25    0.0            26           19\n",
       "4762           25   -2.0            11           10\n",
       "11858          25    2.0            26           18\n",
       "4737           25    2.0            11            9\n",
       "8946           25   -3.0            20           10\n",
       "3073           25   -5.0             7           17\n",
       "11832          25   -3.0            26           17\n",
       "11806          25    2.0            26           16\n",
       "3022           25    3.0             7           15\n",
       "6232           25   -2.0            14           13\n",
       "\n",
       "[14286 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zippedList =  list(zip(cluster_ID, gain_list, day_of_month, hour_of_day))\n",
    "dfObj = pd.DataFrame(zippedList, columns = ['cluster_id' , 'gain', 'day_of_month', 'hour_of_day']) \n",
    "\n",
    "dfObj = dfObj.sort_values(by=['cluster_id'])\n",
    "dfObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x_cluster = dfObj.drop(['gain', 'hour_of_day'], axis=1)\n",
    "\n",
    "df_y_cluster = dfObj.gain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14286, 2) (14286,)\n"
     ]
    }
   ],
   "source": [
    "y_cluster = np.array(df_y_cluster)\n",
    "x_cluster = np.array(df_x_cluster)\n",
    "\n",
    "print(x_cluster.shape, y_cluster.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cluster, x_test_cluster, y_train_cluster, y_test_cluster = train_test_split(x_cluster, y_cluster, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: Station Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              start_date  start_station_code          end_date  \\\n",
      "849566  2018-07-28 22:03                4000  2018-07-28 22:43   \n",
      "784874  2018-07-26 21:28                4000  2018-07-26 21:56   \n",
      "795083  2018-07-27 09:25                4000  2018-07-27 09:30   \n",
      "768486  2018-07-26 14:35                4000  2018-07-26 15:05   \n",
      "556753  2018-07-18 19:24                4000  2018-07-18 19:34   \n",
      "\n",
      "        end_station_code  duration_sec  is_member  \n",
      "849566              6111          2350          1  \n",
      "784874              7067          1673          1  \n",
      "795083              6391           303          1  \n",
      "768486              7031          1805          0  \n",
      "556753              6701           570          0  \n",
      "(953031, 6)\n"
     ]
    }
   ],
   "source": [
    "bike_data_frame = pd.read_csv(\"OD_2018-07.csv\")\n",
    "bike_data_frame = bike_data_frame.sort_values(by=['start_station_code'])\n",
    "print(bike_data_frame.head())\n",
    "print (bike_data_frame.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_station_code</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_station_code</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>is_member</th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>dropoff_cluster</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_weekday</th>\n",
       "      <th>end_hour</th>\n",
       "      <th>end_weekday</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849566</th>\n",
       "      <td>2018-07-28 22:03:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-28 22:43:00+00:00</td>\n",
       "      <td>6111</td>\n",
       "      <td>2350</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784874</th>\n",
       "      <td>2018-07-26 21:28:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-26 21:56:00+00:00</td>\n",
       "      <td>7067</td>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795083</th>\n",
       "      <td>2018-07-27 09:25:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-27 09:30:00+00:00</td>\n",
       "      <td>6391</td>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768486</th>\n",
       "      <td>2018-07-26 14:35:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-26 15:05:00+00:00</td>\n",
       "      <td>7031</td>\n",
       "      <td>1805</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556753</th>\n",
       "      <td>2018-07-18 19:24:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-18 19:34:00+00:00</td>\n",
       "      <td>6701</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      start_date  start_station_code  \\\n",
       "849566 2018-07-28 22:03:00+00:00                4000   \n",
       "784874 2018-07-26 21:28:00+00:00                4000   \n",
       "795083 2018-07-27 09:25:00+00:00                4000   \n",
       "768486 2018-07-26 14:35:00+00:00                4000   \n",
       "556753 2018-07-18 19:24:00+00:00                4000   \n",
       "\n",
       "                        end_date  end_station_code  duration_sec  is_member  \\\n",
       "849566 2018-07-28 22:43:00+00:00              6111          2350          1   \n",
       "784874 2018-07-26 21:56:00+00:00              7067          1673          1   \n",
       "795083 2018-07-27 09:30:00+00:00              6391           303          1   \n",
       "768486 2018-07-26 15:05:00+00:00              7031          1805          0   \n",
       "556753 2018-07-18 19:34:00+00:00              6701           570          0   \n",
       "\n",
       "        pickup_cluster  dropoff_cluster  start_hour  start_weekday  end_hour  \\\n",
       "849566             8.0              8.0          22              5        22   \n",
       "784874             8.0              8.0          21              3        21   \n",
       "795083             8.0              8.0           9              4         9   \n",
       "768486             8.0              8.0          14              3        15   \n",
       "556753             8.0              8.0          19              2        19   \n",
       "\n",
       "        end_weekday  day_of_month  \n",
       "849566            5            28  \n",
       "784874            3            26  \n",
       "795083            4            27  \n",
       "768486            3            26  \n",
       "556753            2            18  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_data_frame['pickup_cluster'] = bike_data_frame['start_station_code']\\\n",
    "                               .map(mydict) \n",
    "bike_data_frame['dropoff_cluster'] = bike_data_frame['end_station_code']\\\n",
    "                               .map(mydict) \\\n",
    "\n",
    "bike_data_frame['start_date'] = pd.to_datetime(bike_data_frame['start_date'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "bike_data_frame['end_date'] = pd.to_datetime(bike_data_frame['end_date'], utc=True, format='%Y-%m-%d %H:%M')\n",
    "bike_data_frame['start_hour'] = bike_data_frame['start_date'].dt.hour\n",
    "bike_data_frame['start_weekday'] = bike_data_frame['start_date'].dt.weekday\n",
    "bike_data_frame['end_hour'] = bike_data_frame['end_date'].dt.hour\n",
    "bike_data_frame['end_weekday'] = bike_data_frame['end_date'].dt.weekday\n",
    "bike_data_frame['day_of_month'] = bike_data_frame['start_date'].dt.day\n",
    "bike_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_station_code</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_station_code</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>is_member</th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>dropoff_cluster</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_weekday</th>\n",
       "      <th>end_hour</th>\n",
       "      <th>end_weekday</th>\n",
       "      <th>day_of_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>849566</th>\n",
       "      <td>2018-07-28 22:03:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-28 22:43:00+00:00</td>\n",
       "      <td>6111</td>\n",
       "      <td>2350</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784874</th>\n",
       "      <td>2018-07-26 21:28:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-26 21:56:00+00:00</td>\n",
       "      <td>7067</td>\n",
       "      <td>1673</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795083</th>\n",
       "      <td>2018-07-27 09:25:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-27 09:30:00+00:00</td>\n",
       "      <td>6391</td>\n",
       "      <td>303</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768486</th>\n",
       "      <td>2018-07-26 14:35:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-26 15:05:00+00:00</td>\n",
       "      <td>7031</td>\n",
       "      <td>1805</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556753</th>\n",
       "      <td>2018-07-18 19:24:00+00:00</td>\n",
       "      <td>4000</td>\n",
       "      <td>2018-07-18 19:34:00+00:00</td>\n",
       "      <td>6701</td>\n",
       "      <td>570</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      start_date  start_station_code  \\\n",
       "849566 2018-07-28 22:03:00+00:00                4000   \n",
       "784874 2018-07-26 21:28:00+00:00                4000   \n",
       "795083 2018-07-27 09:25:00+00:00                4000   \n",
       "768486 2018-07-26 14:35:00+00:00                4000   \n",
       "556753 2018-07-18 19:24:00+00:00                4000   \n",
       "\n",
       "                        end_date  end_station_code  duration_sec  is_member  \\\n",
       "849566 2018-07-28 22:43:00+00:00              6111          2350          1   \n",
       "784874 2018-07-26 21:56:00+00:00              7067          1673          1   \n",
       "795083 2018-07-27 09:30:00+00:00              6391           303          1   \n",
       "768486 2018-07-26 15:05:00+00:00              7031          1805          0   \n",
       "556753 2018-07-18 19:34:00+00:00              6701           570          0   \n",
       "\n",
       "        pickup_cluster  dropoff_cluster  start_hour  start_weekday  end_hour  \\\n",
       "849566            19.0             19.0          22              5        22   \n",
       "784874            19.0              0.0          21              3        21   \n",
       "795083            19.0             19.0           9              4         9   \n",
       "768486            19.0              0.0          14              3        15   \n",
       "556753            19.0              0.0          19              2        19   \n",
       "\n",
       "        end_weekday  day_of_month  \n",
       "849566            5            28  \n",
       "784874            3            26  \n",
       "795083            4            27  \n",
       "768486            3            26  \n",
       "556753            2            18  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data filtering \n",
    "bike_data_frame = bike_data_frame[(bike_data_frame.start_hour>4) & (bike_data_frame.start_hour<24)]\n",
    "bike_data_frame = bike_data_frame[(bike_data_frame.end_hour>4) & (bike_data_frame.end_hour<24)]\n",
    "bike_data_frame = bike_data_frame[(bike_data_frame.duration_sec>0) & (bike_data_frame.duration_sec<7000)]\n",
    "#bike_data_frame = bike_data_frame.drop(['start_date', 'end_date', 'is_member'], axis=1)\n",
    "\n",
    "bike_data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_station_code</th>\n",
       "      <th>end_date</th>\n",
       "      <th>end_station_code</th>\n",
       "      <th>duration_sec</th>\n",
       "      <th>is_member</th>\n",
       "      <th>pickup_cluster</th>\n",
       "      <th>dropoff_cluster</th>\n",
       "      <th>start_hour</th>\n",
       "      <th>start_weekday</th>\n",
       "      <th>end_hour</th>\n",
       "      <th>end_weekday</th>\n",
       "      <th>day_of_month</th>\n",
       "      <th>start_loc</th>\n",
       "      <th>end_loc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204390</th>\n",
       "      <td>2018-07-07 22:36:00+00:00</td>\n",
       "      <td>10002</td>\n",
       "      <td>2018-07-07 22:38:00+00:00</td>\n",
       "      <td>6349</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>546</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866649</th>\n",
       "      <td>2018-07-29 14:40:00+00:00</td>\n",
       "      <td>10002</td>\n",
       "      <td>2018-07-29 14:59:00+00:00</td>\n",
       "      <td>6159</td>\n",
       "      <td>1154</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>29</td>\n",
       "      <td>546</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236630</th>\n",
       "      <td>2018-07-09 07:45:00+00:00</td>\n",
       "      <td>10002</td>\n",
       "      <td>2018-07-09 07:49:00+00:00</td>\n",
       "      <td>6921</td>\n",
       "      <td>285</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>546</td>\n",
       "      <td>454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>694073</th>\n",
       "      <td>2018-07-23 12:20:00+00:00</td>\n",
       "      <td>10002</td>\n",
       "      <td>2018-07-23 12:40:00+00:00</td>\n",
       "      <td>6052</td>\n",
       "      <td>1249</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>546</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332334</th>\n",
       "      <td>2018-07-11 21:45:00+00:00</td>\n",
       "      <td>10002</td>\n",
       "      <td>2018-07-11 21:51:00+00:00</td>\n",
       "      <td>6727</td>\n",
       "      <td>370</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>546</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      start_date  start_station_code  \\\n",
       "204390 2018-07-07 22:36:00+00:00               10002   \n",
       "866649 2018-07-29 14:40:00+00:00               10002   \n",
       "236630 2018-07-09 07:45:00+00:00               10002   \n",
       "694073 2018-07-23 12:20:00+00:00               10002   \n",
       "332334 2018-07-11 21:45:00+00:00               10002   \n",
       "\n",
       "                        end_date  end_station_code  duration_sec  is_member  \\\n",
       "204390 2018-07-07 22:38:00+00:00              6349           160          1   \n",
       "866649 2018-07-29 14:59:00+00:00              6159          1154          0   \n",
       "236630 2018-07-09 07:49:00+00:00              6921           285          1   \n",
       "694073 2018-07-23 12:40:00+00:00              6052          1249          0   \n",
       "332334 2018-07-11 21:51:00+00:00              6727           370          1   \n",
       "\n",
       "        pickup_cluster  dropoff_cluster  start_hour  start_weekday  end_hour  \\\n",
       "204390            25.0             25.0          22              5        22   \n",
       "866649            25.0              8.0          14              6        14   \n",
       "236630            25.0             25.0           7              0         7   \n",
       "694073            25.0              8.0          12              0        12   \n",
       "332334            25.0             25.0          21              2        21   \n",
       "\n",
       "        end_weekday  day_of_month  start_loc  end_loc  \n",
       "204390            5             7        546      306  \n",
       "866649            6            29        546      152  \n",
       "236630            0             9        546      454  \n",
       "694073            0            23        546       56  \n",
       "332334            2            11        546      413  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_loc = (bike_data_frame['start_station_code'].unique())\n",
    "start_loc_mapping = dict(zip(start_loc, \n",
    "                                 range(0, len(start_loc) + 1)))\n",
    "\n",
    "bike_data_frame['start_loc'] = bike_data_frame['start_station_code']\\\n",
    "                               .map(start_loc_mapping) \\\n",
    "                               .astype(int)\n",
    "bike_data_frame['end_loc'] = bike_data_frame['end_station_code'] \\\n",
    "                               .map(start_loc_mapping) \\\n",
    "                               .astype(int)\n",
    "bike_data_frame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_data_frame = bike_data_frame.drop(['start_date', 'end_date', 'is_member'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>gain</th>\n",
       "      <th>dom</th>\n",
       "      <th>hod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>262805</th>\n",
       "      <td>539</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262806</th>\n",
       "      <td>541</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262807</th>\n",
       "      <td>543</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262808</th>\n",
       "      <td>544</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262809</th>\n",
       "      <td>546</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        station_id  gain  dom  hod\n",
       "262805         539   3.0   31   23\n",
       "262806         541   1.0   31   23\n",
       "262807         543   1.0   31   23\n",
       "262808         544   1.0   31   23\n",
       "262809         546   1.0   31   23"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_ID = []\n",
    "gain_list = []\n",
    "day_of_month = []\n",
    "hour_of_day = []\n",
    "\n",
    "for i in range(0,32): # days of month 0-31\n",
    "    for j in range(5,24): # hours of day 5 am - 11 pm\n",
    "        new_frame = bike_data_frame[bike_data_frame['day_of_month'] == i]\n",
    "        new_frame = new_frame[new_frame['start_hour'] == j]\n",
    "        \n",
    "        n_gain = new_frame['start_loc'].value_counts(dropna=True, sort=True)\n",
    "        n_gain = -1*n_gain      \n",
    "        p_gain = new_frame['end_loc'].value_counts(dropna=True, sort=True)\n",
    "        gain = pd.concat([p_gain, n_gain], axis=1)\n",
    "        gain = gain.replace(np.nan, 0)\n",
    "        tot_gain = gain['end_loc'] + gain['start_loc']\n",
    "        tot_gain_ind = tot_gain.index.values\n",
    "        \n",
    "        for x in range(0,len(tot_gain)):\n",
    "            station_ID.append(tot_gain_ind[x])\n",
    "            gain_list.append(tot_gain.iloc[x])\n",
    "            day_of_month.append(i)\n",
    "            hour_of_day.append(j)\n",
    "\n",
    "#print(gain.to_string())\n",
    "#print(p_gain.to_string())\n",
    "#print(n_gain.to_string())\n",
    "#print(negative_gain)\n",
    "#station_ID = np.array(negative_gain)\n",
    "#print(station_ID)\n",
    "\n",
    "zippedList =  list(zip(station_ID, gain_list, day_of_month, hour_of_day))\n",
    "dfObj = pd.DataFrame(zippedList, columns = ['station_id' , 'gain', 'dom', 'hod']) \n",
    "dfObj.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = bike_data_frame.drop('end_station_code', axis=1)\n",
    "df_y = bike_data_frame.end_station_code\n",
    "\n",
    "y = np.array(df_y)\n",
    "x = np.array(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(262810, 3) (262810,)\n"
     ]
    }
   ],
   "source": [
    "df_x = dfObj.drop(['gain'], axis=1)\n",
    "df_y = dfObj.gain\n",
    "\n",
    "# turn x and y into arrays\n",
    "y = np.array(df_y)\n",
    "x = np.array(df_x)\n",
    "\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(714773, 11) (238258, 11)\n",
      "(714773,) (238258,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=5)\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Models for Station Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Train on 714773 samples, validate on 953031 samples\n",
      "Epoch 1/1\n",
      "714773/714773 [==============================] - 62s 87us/step - loss: nan - rmse: nan - val_loss: nan - val_rmse: nan\n"
     ]
    }
   ],
   "source": [
    "# NEURAL NETWORK\n",
    "# ----------------------------------------------------\n",
    "n_col = df_x.shape[1]\n",
    "print(n_col)\n",
    "\n",
    "import keras\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def model() :   #Created a Model using Keras\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dropout(0.5,input_shape=(n_col,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512,activation='relu'))#512 neurons in input layer\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256,activation='relu')) #256 neurons in hidden layer\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, activation='relu')) # 1 neuron in output layer\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1)) #256 neurons in hidden layer\n",
    "    \n",
    "    nadam = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    adadelta =optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "    adgrad = optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
    "    rms = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=nadam,loss='mse', metrics=[rmse])\n",
    "    return model\n",
    "\n",
    "model = model()\n",
    "estimator = model.fit(x=x_train,y=y_train, batch_size=1024, epochs=1, \n",
    "                    verbose=1, validation_data=(x, y), \n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "Train on 714773 samples, validate on 953031 samples\n",
      "Epoch 1/1\n",
      " 79872/714773 [==>...........................] - ETA: 2:07 - loss: nan - rmse: nan"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3e212974bfb4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m estimator = model.fit(x=x_train,y=y_train, batch_size=1024, epochs=1, \n\u001b[1;32m     51\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                     shuffle=True)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_col = df_x.shape[1]\n",
    "print(n_col)\n",
    "\n",
    "import keras\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def model() :   #Created a Model using Keras\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dropout(0.5,input_shape=(n_col,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1024,activation='relu'))#512 neurons in input layer\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512,activation='relu'))#512 neurons in input layer\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256,activation='relu')) #256 neurons in hidden layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128,activation='relu'))  # 128 neurons in hidden layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64,activation='relu'))   # 64 neurons in hidden layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32,activation='relu'))   # 32 neurons in hidden layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16,activation='relu')) # 16 neurons in hidden layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(8,activation='relu')) # 8 neurons in hidden layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1)) # 1 neuron in output layer\n",
    "    \n",
    "    nadam = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    #adadelta =optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "    #adgrad = optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
    "    #rms = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "    \n",
    "    #sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True,clipnorm=0.5)\n",
    "\n",
    "    model.compile(optimizer=nadam,loss='mse', metrics=[rmse])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = model()\n",
    "estimator = model.fit(x=x_train,y=y_train, batch_size=1024, epochs=1, \n",
    "                    verbose=1, validation_data=(x, y), \n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_col = df_x.shape[1]\n",
    "print(n_col)\n",
    "\n",
    "#x_train=x_train.reshape(x_train.shape[0], 1, x_train.shape[1])\n",
    "#x_test=x_test.reshape(x_test.shape[0], 1, x_test.shape[1])\n",
    "\n",
    "import keras\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def model() :   #Created a Model using Keras\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dropout(0.5,input_shape=(n_col, )))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1024,activation='relu'))#512 neurons in input layer\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(512,activation='relu'))#512 neurons in input layer\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256,activation='relu')) #256 neurons in hidden layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128,activation='relu'))  # 128 neurons in hidden layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(64,activation='relu'))   # 64 neurons in hidden layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(32,activation='relu'))   # 32 neurons in hidden layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(16,activation='relu')) # 16 neurons in hidden layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(8,activation='relu')) # 8 neurons in hidden layer\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1)) # 1 neuron in output layer\n",
    "    \n",
    "    nadam = optimizers.Nadam(lr=0.004, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    adadelta =optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "    adgrad = optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
    "    rms = optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0)\n",
    "    \n",
    "    #sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True,clipnorm=0.5)\n",
    "\n",
    "    model.compile(optimizer=rms,loss='mse', metrics=[rmse])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = model()\n",
    "estimator = model.fit(x=x_train,y=y_train, batch_size=2048, epochs=3, \n",
    "                    verbose=1, validation_data=(x_test, y_test),  shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testPredict= model.predict(x_test)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, testPredict)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(953031, 11)\n"
     ]
    }
   ],
   "source": [
    "n_col_x = df_x.shape\n",
    "n_col_y = df_y.shape\n",
    "\n",
    "print(n_col_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-29-28f2214870f3>, line 22)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-29-28f2214870f3>\"\u001b[0;36m, line \u001b[0;32m22\u001b[0m\n\u001b[0;31m    trainScore = (x_train, y_train, verbose=0)\u001b[0m\n\u001b[0m                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "\n",
    "x_train=x_train.reshape(x_train.shape[0], 1, x_train.shape[1])\n",
    "x_test=x_test.reshape(x_test.shape[0], 1, x_test.shape[1])\n",
    "\n",
    "print (x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=64, input_shape=(x_train.shape[1:]), activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=[rmse])\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train,y_train, epochs=1, batch_size=16, verbose=2)\n",
    "trainPredict = model.predict(x_train)\n",
    "testPredict= model.predict(x_test)\n",
    "predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "\n",
    "trainScore = (x_train, y_train, verbose=0)\n",
    "testScore = model.evaluate(x_test, testPredict, verbose=0)\n",
    "print(trainScore)\n",
    "print(\"test score:\", testScore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(714773, 1, 11)\n",
      "(238258, 11)\n",
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 128)               17920     \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 8)                 16        \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 8)                 16        \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 8)                 16        \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 19,036\n",
      "Trainable params: 19,036\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/4\n",
      " - 162s - loss: nan - rmse: nan\n",
      "Epoch 2/4\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN\n",
    "\n",
    "\n",
    "x_train=x_train.reshape(x_train.shape[0], 1,x_train.shape[1])\n",
    "print (x_train.shape)\n",
    "print(x_test.shape)\n",
    "x_test=x_test.reshape(x_test.shape[0], 1, x_test.shape[1])\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=128, input_shape=(x_train.shape[1:]), activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=[rmse])\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train,y_train, epochs=4, batch_size=16, verbose=2)\n",
    "trainPredict = model.predict(x_train)\n",
    "testPredict= model.predict(x_test)\n",
    "\n",
    "predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "\n",
    "trainScore = model.evaluate(x_train, y_train, verbose=0)\n",
    "testScore = model.evaluate(x_test, testPredict, verbose=0)\n",
    "\n",
    "print(\"train score:\",trainScore)\n",
    "print(\"test score:\", testScore)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(testPredict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Dropout\n",
    "\n",
    "#x_train=x_train.reshape(x_train.shape[0], 1,x_train.shape[1])\n",
    "#x_test=x_test.reshape(x_test.shape[0], 1, x_test.shape[1])\n",
    "print (x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=128, input_shape=(x_train.shape[1:]), activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=[rmse])\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train,y_train, epochs=1, batch_size=16, verbose=2)\n",
    "trainPredict = model.predict(x_train)\n",
    "testPredict= model.predict(x_test)\n",
    "predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "\n",
    "trainScore = model.evaluate(x_train, y_train, verbose=0)\n",
    "testScore = model.evaluate(x_test, testPredict, verbose=0)\n",
    "print(\"train score:\",trainScore)\n",
    "print(\"test score:\", testScore)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(testPredict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(y_test, testPredict)\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "ax.set_xlabel('Measured')\n",
    "ax.set_ylabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (testPredict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session() \n",
    "model = Sequential() # Sequential Model\n",
    "model.add(LSTM(20, input_shape=(x_train.shape[1:]))) # (timestep, feature)\n",
    "model.add(Dense(1)) # output = 1\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=[rmse])\n",
    "model.summary()\n",
    "early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=30, verbose=1, callbacks=[early_stop])\n",
    "              \n",
    "trainPredict = model.predict(x_train)\n",
    "testPredict= model.predict(x_test)\n",
    "predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "\n",
    "trainScore = model.evaluate(x_train, y_train, verbose=0)\n",
    "testScore = model.evaluate(x_test, testPredict, verbose=0)\n",
    "print(\"train score:\",trainScore)\n",
    "print(\"test score:\", testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train=x_train.reshape(x_train.shape[0], 1,x_train.shape[1])\n",
    "#x_test=x_test.reshape(x_test.shape[0], 1, x_test.shape[1])\n",
    "print (x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "model1 = Sequential() # Sequential Model\n",
    "model1.add(LSTM(20, input_shape=(x_train.shape[1:]))) # (timestep, feature)\n",
    "model1.add(Dense(1)) # output = 1\n",
    "# Fully connected layer\n",
    "model1.add(Dense(1, activation='relu'))\n",
    "# Dropout for regularization\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(1, activation='relu'))\n",
    "# Dropout for regularization\n",
    "model1.add(Dropout(0.5))\n",
    "model1.compile(loss='mean_squared_error', optimizer='adam', metrics=[rmse])\n",
    "\n",
    "model1.summary()\n",
    "early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=30, verbose=1, callbacks=[early_stop])\n",
    "              \n",
    "trainPredict = model.predict(x_train)\n",
    "testPredict= model.predict(x_test)\n",
    "predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "\n",
    "trainScore = model.evaluate(x_train, y_train, verbose=0)\n",
    "testScore = model.evaluate(x_test, testPredict, verbose=0)\n",
    "print(\"train score:\",trainScore)\n",
    "print(\"test score:\", testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSprop optimizer\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(20, input_shape=(x_train.shape[1:]))) \n",
    "model1.add(Dense(1))\n",
    "model1.add(Dense(1, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(1, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "rmsprop = RMSprop(lr=0.00001, rho=0.9, epsilon=1e-08)\n",
    "model1.compile(loss='mean_squared_error', optimizer=rmsprop, metrics=[rmse] )\n",
    "\n",
    "model1.summary()\n",
    "early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5, batch_size=30, verbose=1, callbacks=[early_stop])\n",
    "              \n",
    "trainPredict = model.predict(x_train)\n",
    "testPredict= model.predict(x_test)\n",
    "predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "\n",
    "trainScore = model.evaluate(x_train, y_train, verbose=0)\n",
    "testScore = model.evaluate(x_test, testPredict, verbose=0)\n",
    "print(\"train score:\",trainScore)\n",
    "print(\"test score:\", testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSprop optimizer\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "model1 = Sequential() # Sequential Model\n",
    "model1.add(LSTM(100, input_shape=(x_train.shape[1:]))) # (timestep, feature)\n",
    "model1.add(Dense(1)) # output = 1\n",
    "model1.add(Dense(1, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(1, activation='relu'))\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "rmsprop = RMSprop(lr=10, rho=9, epsilon=1e-08)\n",
    "model1.compile(loss='mean_squared_error', optimizer=rmsprop, metrics=[rmse] )\n",
    "model1.summary()\n",
    "early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=2, batch_size=30, verbose=1, callbacks=[early_stop])\n",
    "              \n",
    "trainPredict = model.predict(x_train)\n",
    "testPredict= model.predict(x_test)\n",
    "predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "\n",
    "trainScore = model.evaluate(x_train, y_train, verbose=0)\n",
    "testScore = model.evaluate(x_test, testPredict, verbose=0)\n",
    "print(\"train score:\",trainScore)\n",
    "print(\"test score:\", testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADAM optimizer\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(x_train.shape[1:]))) \n",
    "model.add(Dense(1)) \n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "adam = keras.optimizers.Adam( lr=10, beta_1=9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam, metrics=[rmse] )\n",
    "\n",
    "model.summary()\n",
    "early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
    "\n",
    "model.fit(x_train, y_train, epochs=2, batch_size=30, verbose=1, callbacks=[early_stop])\n",
    "              \n",
    "trainPredict = model.predict(x_train)\n",
    "testPredict= model.predict(x_test)\n",
    "predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "\n",
    "trainScore = model.evaluate(x_train, y_train, verbose=0)\n",
    "testScore = model.evaluate(x_test, testPredict, verbose=0)\n",
    "print(\"train score:\",trainScore)\n",
    "print(\"test score:\", testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ADAM optimizer\n",
    "print (x_train.shape)\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "model1 = Sequential() # Sequential Model\n",
    "model1.add(LSTM(100, input_shape=(x_train.shape[1:]))) # (timestep, feature)\n",
    "model1.add(Dense(1)) # output = 1\n",
    "model1.add(Dense(1, activation='tanh'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(1, activation='tanh'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(1)) # output = 1\n",
    "model1.add(Dense(1, activation='tanh'))\n",
    "model1.add(Dropout(0.5))\n",
    "model1.add(Dense(1, activation='tanh'))\n",
    "model1.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "adam = keras.optimizers.Adam( lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "rms = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "model1.compile(loss='mean_squared_error', optimizer=rms, metrics=[rmse])\n",
    "\n",
    "model1.summary()\n",
    "early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
    "\n",
    "model1.fit(x_train, y_train, epochs=10, batch_size=30, verbose=1, callbacks=[early_stop])\n",
    "              \n",
    "trainPredict = model1.predict(x_train)\n",
    "testPredict= model1.predict(x_test)\n",
    "predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "\n",
    "trainScore = model1.evaluate(x_train, y_train, verbose=0)\n",
    "testScore = model1.evaluate(x_test, testPredict, verbose=0)\n",
    "print(\"train score:\",trainScore)\n",
    "print(\"test score:\", testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nadam = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "adadelta =optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "adgrad = optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
    "rms = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Models for Cluster Gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Train on 10603 samples, validate on 14138 samples\n",
      "Epoch 1/1\n",
      "10603/10603 [==============================] - 6s 560us/step - loss: 609.8138 - rmse: 9.8448 - val_loss: 662.8124 - val_rmse: 10.0235\n"
     ]
    }
   ],
   "source": [
    "# NEURAL NETWORK\n",
    "# ----------------------------------------------------\n",
    "n_col = df_x_cluster.shape[1]\n",
    "print(n_col)\n",
    "\n",
    "import keras\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def model() :   #Created a Model using Keras\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dropout(0.5,input_shape=(n_col,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256,activation='relu')) \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1)) \n",
    "    \n",
    "    nadam = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    adadelta =optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "    adgrad = optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
    "    rms = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=nadam,loss='mse', metrics=[rmse])\n",
    "    return model\n",
    "\n",
    "model = model()\n",
    "#estimator = model.fit(x=x_train_cluster,y=y_train_cluster, batch_size=1024, epochs=1, \n",
    "#                    verbose=1, validation_data=(x_cluster, y_cluster), \n",
    "#                    shuffle=True)\n",
    "estimator = model.fit(x=x_train_cluster,y=y_train_cluster, batch_size=1024, epochs=1, \n",
    "                    verbose=1, validation_data=(x_cluster, y_cluster), \n",
    "                    shuffle=True)\n",
    "#model.fit(x_train_cluster,y_train_cluster, epochs=3, batch_size=16, verbose=2)\n",
    "#trainPredict = model.predict(x_test_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Train on 10603 samples, validate on 14138 samples\n",
      "Epoch 1/3\n",
      "10603/10603 [==============================] - 5s 513us/step - loss: 610.0094 - rmse: 9.7812 - val_loss: 662.8253 - val_rmse: 9.9179\n",
      "Epoch 2/3\n",
      "10603/10603 [==============================] - 1s 70us/step - loss: 607.1696 - rmse: 9.7851 - val_loss: 662.9395 - val_rmse: 10.1681\n",
      "Epoch 3/3\n",
      "10603/10603 [==============================] - 1s 64us/step - loss: 606.8375 - rmse: 9.8030 - val_loss: 665.4997 - val_rmse: 10.6086\n"
     ]
    }
   ],
   "source": [
    "# NEURAL NETWORK\n",
    "# ----------------------------------------------------\n",
    "n_col = df_x_cluster.shape[1]\n",
    "print(n_col)\n",
    "\n",
    "import keras\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "def rmse (y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "def model() :   #Created a Model using Keras\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(Dropout(0.5,input_shape=(n_col,)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(512,activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256,activation='relu')) \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, activation='relu')) \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(1)) \n",
    "    \n",
    "    nadam = optimizers.Nadam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\n",
    "    adadelta =optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "    adgrad = optimizers.Adagrad(lr=0.001, epsilon=None, decay=0.0)\n",
    "    rms = optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
    "    \n",
    "    \n",
    "    model.compile(optimizer=nadam,loss='mse', metrics=[rmse])\n",
    "    return model\n",
    "\n",
    "model = model()\n",
    "estimator = model.fit(x=x_train_cluster,y=y_train_cluster, batch_size=2048, epochs=3, \n",
    "                    verbose=1, validation_data=(x_cluster, y_cluster), \n",
    "                    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10603, 1, 2)\n",
      "(3535, 1, 2)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_2 (SimpleRNN)     (None, 128)               16768     \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 8)                 1032      \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 8)                 16        \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dropout_20 (Dropout)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 8)                 16        \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dropout_21 (Dropout)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 8)                 16        \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "dropout_22 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 17,884\n",
      "Trainable params: 17,884\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/3\n",
      " - 4s - loss: 607.9940 - rmse: 9.6074\n",
      "Epoch 2/3\n",
      " - 2s - loss: 607.8846 - rmse: 9.6111\n",
      "Epoch 3/3\n",
      " - 3s - loss: 607.8540 - rmse: 9.6180\n",
      "train score: [607.8633197142944, 9.614990598737412]\n",
      "test score: [0.0, 0.0]\n",
      "(3535, 1, 2)\n",
      "(3535, 1)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Dropout\n",
    "\n",
    "x_train_cluster=x_train_cluster.reshape(x_train_cluster.shape[0], 1,x_train_cluster.shape[1])\n",
    "x_test_cluster=x_test_cluster.reshape(x_test_cluster.shape[0], 1, x_test_cluster.shape[1])\n",
    "print (x_train_cluster.shape)\n",
    "print(x_test_cluster.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(units=128, input_shape=(x_train_cluster.shape[1:]), activation=\"relu\"))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(8, activation=\"relu\")) \n",
    "model.add(Dense(1))\n",
    "model.add(Dropout(0.5))\n",
    "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=[rmse])\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train_cluster,y_train_cluster, epochs=3, batch_size=16, verbose=2)\n",
    "trainPredict = model.predict(x_train_cluster)\n",
    "testPredict= model.predict(x_test_cluster)\n",
    "predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "\n",
    "trainScore = model.evaluate(x_train_cluster, y_train_cluster, verbose=0)\n",
    "testScore = model.evaluate(x_test_cluster, testPredict, verbose=0)\n",
    "print(\"train score:\",trainScore)\n",
    "print(\"test score:\", testScore)\n",
    "\n",
    "print(x_test_cluster.shape)\n",
    "print(testPredict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10603, 1, 2)\n",
      "(3535, 1, 2)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               41200     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 101       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 1)                 0         \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 1)                 2         \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 41,305\n",
      "Trainable params: 41,305\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Epoch 1/2\n",
      "10603/10603 [==============================] - 4s 357us/step - loss: 607.8677 - rmse: 9.6004\n",
      "Epoch 2/2\n",
      "10603/10603 [==============================] - 2s 215us/step - loss: 607.8677 - rmse: 9.6004\n",
      "train score: [607.8676789645417, 9.600396047748845]\n",
      "test score: [0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "#ADAM optimizer\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense \n",
    "import keras.backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#x_train_cluster=x_train_cluster.reshape(x_train_cluster.shape[0], 1,x_train_cluster.shape[1])\n",
    "#x_test_cluster=x_test_cluster.reshape(x_test_cluster.shape[0], 1, x_test_cluster.shape[1])\n",
    "print (x_train_cluster.shape)\n",
    "print(x_test_cluster.shape)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, input_shape=(x_train_cluster.shape[1:]))) \n",
    "model.add(Dense(1)) \n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "adam = keras.optimizers.Adam( lr=10, beta_1=9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss='mean_squared_error', optimizer=adam, metrics=[rmse] )\n",
    "\n",
    "model.summary()\n",
    "early_stop = EarlyStopping(monitor='loss', patience=1, verbose=1)\n",
    "\n",
    "model.fit(x_train_cluster, y_train_cluster, epochs=2, batch_size=30, verbose=1, callbacks=[early_stop])\n",
    "              \n",
    "trainPredict = model.predict(x_train_cluster)\n",
    "testPredict= model.predict(x_test_cluster)\n",
    "predicted=np.concatenate((trainPredict,testPredict),axis=0)\n",
    "\n",
    "trainScore = model.evaluate(x_train_cluster, y_train_cluster, verbose=0)\n",
    "testScore = model.evaluate(x_test_cluster, testPredict, verbose=0)\n",
    "print(\"train score:\",trainScore)\n",
    "print(\"test score:\", testScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
